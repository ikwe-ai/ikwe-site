# ikwe.ai approved copy (single source of truth)

## Source notes
- Consolidates approved messaging from `ikwe_content_distribution_v2.md` plus research/methodology details aligned with the EQ Safety Benchmark materials and site content.
- Use **behavioral emotional safety** and **EQ Safety Benchmark** consistently in all pages and marketing touchpoints.

---

## Content blocks

### Block A — Mission & positioning (approved)
**Short mission line:**
> We measure behavioral emotional safety in AI — how emotional risk is introduced and managed within the interaction.

**Positioning statement:**
> Most benchmarks assume harm comes from users. We measure what the AI response itself introduces when vulnerability is present.

**One-line differentiator:**
> Behavioral emotional safety measures what systems *do* under distress, not just whether they recognize emotion.

---

### Block B — Home hero (approved)
**Hero headline:**
> Behavioral Emotional Safety, Measured.

**Hero subtitle (use verbatim):**
> Most AI systems introduce emotional risk at first contact when users disclose vulnerability.

**Supporting line:**
> The EQ Safety Benchmark measures who introduces risk, when it happens, and whether it is repaired within the interaction window.

---

### Block C — Core findings (approved)
**Key findings summary (use as short bullets or stat cards):**
- **54.7%** of baseline AI responses introduced emotional risk at first contact.
- **43%** of those responses showed no corrective behavior within the interaction window.
- Models most fluent at naming emotion often performed **worst** on behavioral safety under distress.

**Interpretive line:**
> These were not toxic replies. They were supportive-sounding responses that mirrored distress, reinforced unverified beliefs, or escalated emotion instead of regulating it.

**CTA line:**
> Full data & framework: ikwe.ai/emotional-safety-gap

---

### Block D — Benchmark definition (approved + research summary)
**Definition:**
> The EQ Safety Benchmark evaluates **behavioral emotional safety** — what AI systems do once emotional vulnerability is present. It does not measure emotion recognition, sentiment accuracy, or policy compliance.

**Gap statement:**
> A system can recognize emotion accurately and still behave in ways that increase risk. This benchmark evaluates what happens after vulnerability appears.

---

### Block E — Research methodology (summary)
**Two-stage evaluation:**
1. **Baseline Emotional Safety Gate (pass/fail):** Does the initial response meet minimum emotional safety criteria, or does it introduce emotional risk at first contact?
2. **Behavioral dimension scoring:** Applied only if Stage 1 passes; scores regulation, validation, agency, containment, and escalation awareness across 8 weighted dimensions.

**Response collection conditions:**
- Default interaction structure per platform
- No custom system prompts or behavioral guidance
- Fresh, no-history sessions for manual tests
- Post-hoc evaluation with a consistent rubric

**Scenario sources:**
- 79 scenarios selected from an initial pool of 1,000 across public counseling datasets
- Scenarios include explicit + implicit distress signals and varied intensity levels

---

### Block F — About narrative (approved)
**About intro:**
> ikwe.ai is independent research on behavioral emotional safety in conversational AI.

**What we do:**
> We measure how AI responses introduce and manage emotional risk during moments of human vulnerability — and whether that risk is repaired within the interaction.

**Core insight line:**
> The most dangerous failures don't look toxic — they look supportive.

**Organization:**
> ikwe.ai is a research initiative of Visible Healing Inc., an Iowa-based AI research company focused on emotional safety infrastructure. We operate independently, without funding from the AI companies we evaluate.

---

### Block G — Privacy summary (approved)
**Privacy short summary (for footer/overview cards):**
- We collect inquiry details you provide (name, email, company, messages).
- We collect standard analytics (browser, pages visited, referral source, general location).
- We use data to respond to requests, provide services, improve the site, and send updates when opted in.
- We do not sell personal information.
- Evaluation scenarios use synthetic/anonymized data; we do not use identifiable client conversations for benchmark development.

**Contact line:**
> Privacy requests: stephanie@ikwe.ai

---

### Block H — Terms summary (approved)
**Terms short summary (for footer/overview cards):**
- ikwe.ai is a research and evaluation initiative focused on behavioral emotional safety in AI systems.
- The site is **not** a crisis or therapy service.
- Findings describe observed behavioral patterns under test conditions and do not claim real-world outcomes.
- Content is protected IP; citation allowed with attribution.

**Contact line:**
> Terms questions: research@ikwe.ai

---

## Page section map

### Home page
- **Hero:** Block B (Hero headline + subtitle + supporting line)
- **Key findings / stats:** Block C
- **Mission / differentiator strip:** Block A (short mission line + differentiator)

### Research page
- **Benchmark definition:** Block D
- **Methodology overview:** Block E
- **Findings summary:** Block C (lead-in sentence + stats)

### About page
- **Hero + narrative:** Block F (About intro + What we do + Core insight)
- **Organization:** Block F (Organization)

### Privacy page
- **Overview summary card:** Block G (summary bullets + contact line)

### Terms page
- **Overview summary card:** Block H (summary bullets + contact line)

---

## Lightweight review checklist
- [ ] Terminology uses **behavioral emotional safety** and **EQ Safety Benchmark** consistently.
- [ ] Stats match approved values (54.7%, 43%, 79 scenarios, 1,000 → 79 selection, 8 dimensions).
- [ ] Hero subtitle uses the approved wording about AI introducing emotional risk at first contact.
- [ ] No claims imply clinical outcomes, therapeutic efficacy, or real-world harm.
- [ ] Any new copy is added here first before being placed on pages.
